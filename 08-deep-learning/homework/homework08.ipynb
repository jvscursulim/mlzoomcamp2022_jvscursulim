{"cells":[{"cell_type":"markdown","metadata":{},"source":["# MLZoomcamp 2022 - Session #8 - Homework\n","\n","Author: Jos√© Victor"]},{"cell_type":"markdown","metadata":{},"source":["* Dataset: [Dino or Dragon?](https://www.kaggle.com/datasets/agrigorev/dino-or-dragon)"]},{"cell_type":"markdown","metadata":{},"source":["In the lectures we saw how to use a pre-trained neural network. In the homework, we'll train a much smaller model from scratch."]},{"cell_type":"markdown","metadata":{},"source":["## Imports"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["## Data Preparation\n","\n","The dataset contains around 1900 images of dinos and around 1900 images of dragons.\n","\n","The dataset contains separate folders for training and validation."]},{"cell_type":"markdown","metadata":{},"source":["## Model\n","\n","For this homework we will use Convolutional Neural Network (CNN). Like in the lectures, we'll use Keras.\n","\n","You need to develop the model with following structure:\n","\n","* The shape for input should be `(150, 150, 3)`\n","* Next, create a convolutional layer (`Conv2D`)\n","    * Use 32 filters\n","    * Kernel size should be `(3, 3)` (that's the size of the filter)\n","    * Use `relu` as activation\n","* Reduce the size of the feature map with max pooling (`MaxPooling2D`)\n","    * Set the pooling size to `(2, 2)`\n","* Turn the multi-dimensional result into vectors using a `Flatten` layer\n","* Next, add a `Dense` layer with 64 neurons and `relu` activation\n","* Finally, create the `Dense` layer with 1 neuron - this will be the output\n","    * The output layer should have an activation - use the appropriate activation for the binary classification case\n","\n","As optimizer use `SDG` with the following parameters:\n","\n","* `SDG(lr=0.002, momentum=0.8)`\n","\n","For clarification about kernel size and max pooling, check [Office Hours](https://www.youtube.com/watch?v=1WRgdBTUaAc)."]},{"cell_type":"markdown","metadata":{},"source":["## Question 1\n","\n","Since we have a binary classification problem, what is the best loss function for us?\n","\n","* (X) `binary crossentropy`\n","* ( ) `focal loss`\n","* ( ) `mean squared error`\n","* ( ) `categorical crossentropy`\n","\n","Note: since we specify an activation for the output layer, we don't need to set `from_logits=True`"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["## Question 2\n","\n","What's the total number of parameters of the model? You can use the `summary` method for that.\n","\n","* ( ) 9215873\n","* ( ) 11215873\n","* ( ) 14215873\n","* ( ) 19215873"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["## Generators and Training\n","\n","For the next two questions, use the following data generator for both train and validation:\n","\n","```python\n","ImageDataGenerator(rescale=1./255)\n","```\n","\n","* We don't need to do any additional pre-processing for the images.\n","* When reading the data from train/val directories, check the `class_mode` parameter. Which value should it be for a binary classification problem?\n","* Use `batch_size=20`\n","* Use `shuffle=True` for both training and validation\n","\n","For training use `.fit()` with the following params:\n","\n","```python\n","model.fit(\n","    train_generator,\n","    epochs=10,\n","    validation_data=validation_generator\n",")\n","```"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["## Question 3\n","\n","What is the median of training accuracy for all the epochs for this model?\n","\n","* ( ) 0.40\n","* ( ) 0.60\n","* ( ) 0.90\n","* ( ) 0.20"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["## Question 4\n","\n","What is the standard deviation of training loss for all the epochs for this model?\n","\n","* ( ) 0.11\n","* ( ) 0.66\n","* ( ) 0.99\n","* ( ) 0.33"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["## Data Augmentation\n","\n","For the next two questions, we'll generate more data using data augmentations.\n","\n","Add the following augmentations to your training data generator:\n","\n","* `rotation_range=40`\n","* `width_shift_range=0.2`\n","* `height_shift_range=0.2`\n","* `shear_range=0.2`\n","* `zoom_range=0.2`\n","* `horizontal_flip=True`\n","* `fill_mode='nearest'`"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["## Question 5\n","\n","Let's train our model for 10 more epochs using the same code as previously. Make sure you don't re-create the model - we want to continue training the model we already started training.\n","\n","What is the mean of validation loss for all the epochs for the model trained with augmentations?\n","\n","* ( ) 0.15\n","* ( ) 0.77\n","* ( ) 0.37\n","* ( ) 0.97"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["## Question 6 \n","\n","What's the average of validation accuracy for the last 5 epochs (from 6 to 10) for the model trained with augmentations?\n","\n","* ( ) 0.84\n","* ( ) 0.54\n","* ( ) 0.44\n","* ( ) 0.24"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3.8.10 ('env': venv)","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.8.10"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"407e90332109578e0065ba18671dbaca2b32e43f8b825728b86719da6231e0a7"}}},"nbformat":4,"nbformat_minor":2}
