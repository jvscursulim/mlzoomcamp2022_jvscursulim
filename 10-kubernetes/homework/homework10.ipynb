{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLZoomcamp 2022 - Session #10 - Homework\n",
    "\n",
    "Author: José Victor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the image\n",
    "\n",
    "Clone the course repo if you haven't:\n",
    "\n",
    "ˋˋˋbash\n",
    "git clone https://github.com/alexeygrigorev/mlbookcamp-code.git\n",
    "ˋˋˋ\n",
    "\n",
    "Go to the ˋcourse-zoomcamp/cohorts/2022/05-deployment/homeworkˋ folder and execute the following:\n",
    "\n",
    "ˋˋˋbash\n",
    "docker build -t zoomcamp-model:v001 .\n",
    "ˋˋˋ\n",
    "\n",
    "Note: If you have troubles building the image, you can use the image we built and published to docker hub: ˋsvizor42/zoomcamp-model:v001ˋ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "Run it to test that it's working locally:\n",
    "\n",
    "ˋˋˋbash\n",
    "docker run -it --rm -p 9696:9696 zoomcamp-model:v001\n",
    "ˋˋˋ\n",
    "\n",
    "And in another terminal, execute ˋq6_test.pyˋ file:\n",
    "\n",
    "ˋˋˋbash\n",
    "python q6_test.py\n",
    "ˋˋˋ\n",
    "\n",
    "You should see this:\n",
    "\n",
    "ˋˋˋ\n",
    "{'get_card': True, 'get_card_probability': <value>}\n",
    "ˋˋˋ\n",
    "\n",
    "Here ˋ<value>ˋ is the probability of getting a credit card. You need to choose the right one.\n",
    "\n",
    "* ( ) 0.289\n",
    "* ( ) 0.502\n",
    "* ( ) 0.769\n",
    "* ( ) 0.972\n",
    "\n",
    "Now you can stop the container running in Docker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing ˋkubectlˋ and ˋkindˋ\n",
    "\n",
    "You need to install:\n",
    "\n",
    "* ˋkubectlˋ - [https://kubernetes.io/docs/tasks/tools/](https://kubernetes.io/docs/tasks/tools/) (you might already have it - check before installing)\n",
    "* ˋkindˋ - [https://kind.sigs.k8s.io/docs/user/quick-start/](https://kind.sigs.k8s.io/docs/user/quick-start/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "What's the version of ˋkindˋ that you have\n",
    "\n",
    "Use ˋkind --versionˋ to find out.\n",
    "\n",
    "### Creating a cluster\n",
    "\n",
    "Now let's create a cluster with ˋkindˋ:\n",
    "\n",
    "ˋˋˋ\n",
    "kind create cluster\n",
    "ˋˋˋ\n",
    "\n",
    "And check with ˋkubectlˋ that it was successfully created:\n",
    "\n",
    "ˋˋˋ\n",
    "kubectl cluster-info\n",
    "ˋˋˋ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "What's the smallest deployable computing unit that we can create and manage in Kubernetes (ˋkindˋ in our case)\n",
    "\n",
    "* ( ) Node\n",
    "* ( ) Pod\n",
    "* ( ) Deployment\n",
    "* ( ) Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "Now let's test if everything works. Use ˋkubectlˋ to get the list of running services.\n",
    "\n",
    "What's the ˋTypeˋ of the service that is already running there\n",
    "\n",
    "* ( ) ClusterIP\n",
    "* ( ) NodePort\n",
    "* ( ) LoadBalancer\n",
    "* ( ) ExternalName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "\n",
    "To be able to use the docker image we previously created (ˋzoomcamp-model:v001ˋ), we need to register it with ˋkindˋ.\n",
    "\n",
    "What's the command we need to run for that\n",
    "\n",
    "* ( ) ˋkind create clusterˋ\n",
    "* ( ) ˋkind build node-imageˋ\n",
    "* ( ) ˋkind load docker-imageˋ\n",
    "* ( ) ˋkubectl applyˋ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "\n",
    "Now let's create a deployment config (e.g. ˋdeployment.yamlˋ):\n",
    "\n",
    "ˋˋˋyaml\n",
    "apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  name: credit-card\n",
    "spec:\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      app: credit-card\n",
    "  replicas: 1\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        app: credit-card\n",
    "    spec:\n",
    "      containers:\n",
    "      - name: credit-card\n",
    "        image: <Image>\n",
    "        resources:\n",
    "          requests:\n",
    "            memory: \"64mi\"\n",
    "            cpu: \"100m\"\n",
    "          limits:\n",
    "            memory: <Memory>\n",
    "            cpu: <CPU>\n",
    "          ports:\n",
    "          - containerPort: <Port>\n",
    "ˋˋˋ\n",
    "\n",
    "Replace ˋ<Image>ˋ, ˋ<Memory>ˋ, ˋ<CPU>ˋ, ˋ<Port>ˋ with the correct values.\n",
    "\n",
    "What is the value for ˋ<Port>ˋ\n",
    "\n",
    "Apply this deployment using the appropriate command and get a list of running Pods. You can see one running Pod."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7\n",
    "\n",
    "Let's create a service for this deployment (ˋservice.yamlˋ)ˋ:\n",
    "\n",
    "ˋˋˋyaml\n",
    "apiVersion: v1\n",
    "kind: Service\n",
    "metadata:\n",
    "  name: <Service name>\n",
    "spec:\n",
    "  type: LoadBalancer\n",
    "  selector:\n",
    "    app: <>\n",
    "  ports:\n",
    "  - port: 80\n",
    "    targetPort: <PORT>\n",
    "ˋˋˋ\n",
    "\n",
    "Fill it in. What do we need to write instead of ˋ<>ˋ\n",
    "\n",
    "Apply this config file.\n",
    "\n",
    "### Testing the service\n",
    "\n",
    "We can test our service locally by forwarding the port 9696 on our computer to the port 80 on the service:\n",
    "\n",
    "ˋˋˋ\n",
    "kubectl port-forward service/<Service name> 9696:80\n",
    "ˋˋˋ\n",
    "\n",
    "Run ˋq6_test.pyˋ (from the homework 5) once again to verify that everything is working. You should get the same result as in Question 1.\n",
    "\n",
    "### Autoscaling\n",
    "\n",
    "Now we're going to use a [HorizontalPodAutoscaler]() (HPA for short) that automatically updates a workload resource (such as our deployment), with the aim of automatically scalling the workload to match demand.\n",
    "\n",
    "Use the following command to create the HPA:\n",
    "\n",
    "ˋˋˋ\n",
    "kubectl autoscale deployment credit-card --name credit-card-hpa --cpu-percent=20 --min=1 --max=3\n",
    "ˋˋˋ\n",
    "\n",
    "You can check the current status of the new HPA by running:\n",
    "\n",
    "ˋˋˋ\n",
    "kubectl get hpa\n",
    "ˋˋˋ\n",
    "\n",
    "The output should be similar to the next:\n",
    "\n",
    "ˋˋˋ\n",
    "NAME            REFERENCE               TARGETS   MINPODS   MAXPODS   REPLICAS  AGE\n",
    "credit-card-hpa Deployment/credit-card  1%/20%    1         3         1         27s\n",
    "ˋˋˋ\n",
    "\n",
    "ˋTARGETˋ column shows the average CPU consumption across all the Pods controlled by the corresponding deployment. Current CPU consumption is about 0% as there are no clients sending requests to the server.\n",
    "\n",
    "Note: In case the HPA instance doesn't run properly, try to install the latest Metrics Server release from the ˋcomponents.yamlˋ manifest:\n",
    "\n",
    "ˋˋˋ\n",
    "kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml\n",
    "ˋˋˋ\n",
    "\n",
    "### Increase the load\n",
    "\n",
    "Let's see how the autoscaler reacts to increasing the load. To do this, we can slightly modify the existing ˋq6_test.pyˋ script by putting the operator that sends the request to the credit-card service into a loop.\n",
    "\n",
    "ˋˋˋpython\n",
    "while True:\n",
    "    sleep(0.1)\n",
    "    response = requests.post(url, json=client).json()\n",
    "    print(response)\n",
    "ˋˋˋ\n",
    "\n",
    "Now you can run this script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 8 (optional)\n",
    "\n",
    "Run ˋkubectl get hpa php-apache --watchˋ command to monitor how the autoscaler performs. Within a minute or so, you should see the higher CPU load; and then - more replicas. What was the maximum amount of the replicas during this test\n",
    "\n",
    "* ( ) 1\n",
    "* ( ) 2\n",
    "* ( ) 3\n",
    "* ( ) 4\n",
    "\n",
    "Note: It may take a few minutes to stabilize the number of replicas. Since the amount of load is not controlled in any way it may happen that the final number of replicas will differ from initial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ad933181bd8a04b432d3370b9dc3b0662ad032c4dfaa4e4f1596c548f763858"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
